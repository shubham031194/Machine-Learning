# **Logistic Regression**
Logistic Regression is a supervised machine learning algorithm primarily used for classification tasks, specifically binary classification problems. It predicts the probability of an input belonging to one of two categories, typically denoted as class 0 or class 1.

While both Logistic Regression and Linear Regression are forms of regression, they serve different purposes:
1. **Linear Regression:** Predicts a continuous output based on input variables. It is used for regression tasks where the dependent variable is continuous, such as predicting house prices.
2. **Logistic Regression:** Predicts the probability of a class label (often binary) based on input variables. It is used for classification tasks where the dependent variable is categorical, such as determining whether an email is spam or not.
The distinction lies in the output: Logistic Regression outputs a probability value between 0 and 1, while Linear Regression gives a continuous number, which could be anything between negative and positive infinity. This distinction is key for classification tasks.

### **Why Not Use Linear Regression for Classification?**
When trying to solve classification problems with Linear Regression, some key issues arise:
1. **Outliers:** Linear regression is sensitive to outliers, which can lead to predictions outside the bounds of valid probabilities (i.e., less than 0 or greater than 1), which is not useful for classification.
2. **Boundaries:** Linear regression does not have a mechanism to produce a probability-like output, as probabilities are naturally bounded between 0 and 1. Without transformation, the continuous output is not interpretable for classification.

This is where Logistic Regression comes in, using a sigmoid function to map outputs into a valid probability range.

## **Sigmoid Function: The Core of Logistic Regression**
The sigmoid function is a mathematical transformation used to map any real-valued number into a value between 0 and 1. This is essential for logistic regression because we need outputs that represent probabilities.

The sigmoid function is given by:

                          ![](https://github.com/shubham031194/Machine-Learning/blob/main/assets/AI_space.png)

Where:

* x is the linear combination of input features and weights (i.e.,  ![](https://github.com/shubham031194/Machine-Learning/blob/main/assets/AI_space.png) ).
* e is the mathematical constant Euler‚Äôs number (ùëí ‚âà 2.718).

This function has two important properties:
1. The output is bounded between 0 and 1, making it suitable for probabilities.
2. The function is S-shaped (sigmoidal), meaning small negative inputs will result in values close to 0, while large positive inputs will result in values close to 1.\

## **Decision Rule in Logistic Regression:**

Once the sigmoid function produces a probability, we can classify the output based on a threshold (commonly 0.5):
* If the probability ùëÉ ‚â• 0.5, classify the input as class 1.
* If the probability ùëÉ < 0.5, classify the input as class 0.

## **Hypothesis in Logistic Regression**
In Linear Regression, the hypothesis is represented as a linear equation:

